{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84fc67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from fancyimpute import IterativeImputer\n",
    "import sklearn\n",
    "print(format(sklearn.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa3ef2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url=\"F:\\Downloads\\Khidmah_Data.xlsx\"\n",
    "dataset=pandas.read_excel(url);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02c61be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age Smoke  Dia_family_mem  HTN_family  IHD/MI_family  Stroke_family  \\\n",
      "0    32.0   Yes             8.0         NaN            NaN            NaN   \n",
      "1    60.0    No             0.0         NaN            NaN            NaN   \n",
      "2    50.0    No             7.0         NaN            NaN            NaN   \n",
      "3    48.0    No             NaN         2.0            NaN            NaN   \n",
      "4    44.0    No             8.0         NaN            NaN            NaN   \n",
      "..    ...   ...             ...         ...            ...            ...   \n",
      "664  35.0    No             8.0         3.0            1.0            1.0   \n",
      "665  46.0    No             NaN         NaN            NaN            NaN   \n",
      "666  62.0    No             NaN         NaN            NaN            NaN   \n",
      "667  48.0    No             3.0         2.0            1.0            1.0   \n",
      "668  42.0    No             8.0         NaN            NaN            NaN   \n",
      "\n",
      "     Amputation_family  Height  Weight    BMI  ...   HDL    LDL    SGPT  \\\n",
      "0                  NaN   170.0    69.0  23.88  ...  67.0    NaN    24.0   \n",
      "1                  NaN   154.0    72.0  30.36  ...   NaN    NaN  3601.0   \n",
      "2                  NaN   165.0    57.0  20.94  ...   NaN    NaN    22.0   \n",
      "3                  NaN   148.0    70.0  31.96  ...   NaN    NaN  2110.0   \n",
      "4                  NaN   163.0    65.0  24.46  ...   NaN    NaN    29.0   \n",
      "..                 ...     ...     ...    ...  ...   ...    ...     ...   \n",
      "664                NaN   152.0    68.0  29.43  ...   NaN    NaN    31.0   \n",
      "665                NaN   169.0    72.0  25.21  ...   NaN    NaN    32.0   \n",
      "666                NaN   150.0    48.0  21.33  ...   NaN    NaN    27.0   \n",
      "667                NaN   160.0    61.0  23.83  ...   NaN    NaN    15.0   \n",
      "668                NaN   154.0    57.0  24.03  ...  45.0  112.0    52.0   \n",
      "\n",
      "     HbAlc  Urea  Creatinine  S.TSH  RBS  U.Acid  Diagnosis DM Type  \n",
      "0      NaN   NaN        0.80    NaN  NaN     NaN                1.0  \n",
      "1      NaN   NaN        0.17    NaN  NaN     NaN                1.0  \n",
      "2      NaN   NaN        0.80    NaN  NaN     NaN                1.0  \n",
      "3      NaN   NaN        0.80    NaN  NaN     NaN                1.0  \n",
      "4      NaN   NaN        0.80    NaN  NaN     NaN                1.0  \n",
      "..     ...   ...         ...    ...  ...     ...                ...  \n",
      "664    NaN   NaN        0.80    NaN  NaN     NaN                1.0  \n",
      "665    NaN   NaN        0.90    NaN  NaN     NaN                1.0  \n",
      "666    NaN   NaN        1.10    NaN  NaN     NaN                1.0  \n",
      "667    NaN   NaN        0.70    NaN  NaN     NaN                1.0  \n",
      "668    NaN   NaN        0.80    NaN  NaN     NaN                1.0  \n",
      "\n",
      "[669 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c580d677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dia_family_mem</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTN_family</th>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IHD/MI_family</th>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke_family</th>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amputation_family</th>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulse</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bp</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of detection</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fbs_first</th>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABF_first</th>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGPT_first</th>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBS</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hb</th>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESR</th>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TC</th>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poly</th>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lymph</th>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mono</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baso</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eosin</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABF</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Na+</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-</th>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cl</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC03</th>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.Chol</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TG</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDL</th>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDL</th>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGPT</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HbAlc</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urea</th>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creatinine</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.TSH</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBS</th>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.Acid</th>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis DM Type</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset\n",
       "Age                     18\n",
       "Smoke                   62\n",
       "Dia_family_mem         151\n",
       "HTN_family             382\n",
       "IHD/MI_family          470\n",
       "Stroke_family          466\n",
       "Amputation_family      521\n",
       "Height                  40\n",
       "Weight                  27\n",
       "BMI                     49\n",
       "Pulse                   72\n",
       "Bp                      65\n",
       "Date of detection      185\n",
       "Fbs_first              458\n",
       "ABF_first              416\n",
       "SGPT_first             650\n",
       "FBS                     34\n",
       "Hb                     527\n",
       "ESR                    525\n",
       "TC                     593\n",
       "Poly                   553\n",
       "Lymph                  534\n",
       "Mono                   537\n",
       "Baso                   600\n",
       "Eosin                  537\n",
       "ABF                     30\n",
       "Na+                    664\n",
       "K-                     667\n",
       "Cl                     664\n",
       "HC03                   668\n",
       "T.Chol                  65\n",
       "TG                      66\n",
       "HDL                    470\n",
       "LDL                    472\n",
       "SGPT                   104\n",
       "HbAlc                  600\n",
       "Urea                   636\n",
       "Creatinine              68\n",
       "S.TSH                  664\n",
       "RBS                    661\n",
       "U.Acid                 650\n",
       "Diagnosis DM Type       64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing data\n",
    "Nas=pandas.concat([dataset.isnull().sum()],axis=1,keys=[\"Dataset\"])\n",
    "Nas[Nas.sum(axis=1)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21afac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age Smoke  Dia_family_mem  Height  Weight    BMI  Pulse      Bp  \\\n",
      "0    32.0   Yes             8.0   170.0    69.0  23.88   76.0  120/80   \n",
      "1    60.0    No             0.0   154.0    72.0  30.36   76.0  120/80   \n",
      "2    50.0    No             7.0   165.0    57.0  20.94   76.0  120/80   \n",
      "3    48.0    No             NaN   148.0    70.0  31.96   72.0  150/90   \n",
      "4    44.0    No             8.0   163.0    65.0  24.46   76.0  120/80   \n",
      "..    ...   ...             ...     ...     ...    ...    ...     ...   \n",
      "664  35.0    No             8.0   152.0    68.0  29.43   96.0  120/80   \n",
      "665  46.0    No             NaN   169.0    72.0  25.21   76.0  120/80   \n",
      "666  62.0    No             NaN   150.0    48.0  21.33  100.0  120/80   \n",
      "667  48.0    No             3.0   160.0    61.0  23.83  110.0  120/80   \n",
      "668  42.0    No             8.0   154.0    57.0  24.03  100.0  120/80   \n",
      "\n",
      "     Date of detection   FBS  \n",
      "0               2012.0  15.7  \n",
      "1                  NaN   7.3  \n",
      "2               2019.0  17.1  \n",
      "3               2015.0   8.5  \n",
      "4               2019.0   7.9  \n",
      "..                 ...   ...  \n",
      "664             2013.0  14.0  \n",
      "665             2009.0  10.3  \n",
      "666             2005.0  18.5  \n",
      "667             2000.0  13.8  \n",
      "668             2012.0  13.4  \n",
      "\n",
      "[669 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_to_remove = ['HTN_family', 'IHD/MI_family','Stroke_family','Amputation_family','Fbs_first','ABF_first','SGPT_first','Hb','ESR','TC','Poly','Lymph','Mono','Baso','Eosin','Na+','K-','Cl','HC03','HDL','LDL','HbAlc','Urea','S.TSH','RBS','U.Acid','Diagnosis DM Type','ABF', 'T.Chol', 'TG', 'SGPT', 'Creatinine']\n",
    "\n",
    "# Remove the columns using the drop() function\n",
    "dataset.drop(columns_to_remove, axis=1, inplace=True)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ccbe3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns containing string values\n",
    "string_cols = [col for col in dataset.columns if dataset[col].dtype == 'object']\n",
    "\n",
    "# Convert binary string columns to numeric\n",
    "dataset['Smoke'] = dataset['Smoke'].map({'Yes': 0, 'No': 1})\n",
    "\n",
    "bp_col = 'Bp'\n",
    "\n",
    "# Split the blood pressure column into two columns\n",
    "bp_split = dataset[bp_col].str.split('/', expand=True)\n",
    "dataset['systolic'] = bp_split[0].astype(float)\n",
    "dataset['diastolic'] = bp_split[1].astype(float)\n",
    "\n",
    "# Drop the original blood pressure column\n",
    "dataset.drop(bp_col, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cae112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_imputer_knn_sklearn=dataset.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e00720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                   18\n",
       "Smoke                 63\n",
       "Dia_family_mem       151\n",
       "Height                40\n",
       "Weight                27\n",
       "BMI                   49\n",
       "Pulse                 72\n",
       "Date of detection    185\n",
       "FBS                   34\n",
       "systolic              68\n",
       "diastolic             68\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_imputer_knn_sklearn.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e21f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ade9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnimputer= KNNImputer(n_neighbors=3)\n",
    "dataset_imputer_knn_sklearn.iloc[:,:]=knnimputer.fit_transform(dataset_imputer_knn_sklearn)\n",
    "# save the updated dataset\n",
    "dataset_imputer_knn_sklearn.to_csv('updated_datasetknn.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae013368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Dia_family_mem</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Date of detection</th>\n",
       "      <th>FBS</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>23.88</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>15.7</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2013.666667</td>\n",
       "      <td>7.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.94</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>17.1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.96</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>8.5</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>24.46</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>7.9</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Smoke  Dia_family_mem  Height  Weight    BMI  Pulse  \\\n",
       "0  32.0    0.0             8.0   170.0    69.0  23.88   76.0   \n",
       "1  60.0    1.0             0.0   154.0    72.0  30.36   76.0   \n",
       "2  50.0    1.0             7.0   165.0    57.0  20.94   76.0   \n",
       "3  48.0    1.0             6.0   148.0    70.0  31.96   72.0   \n",
       "4  44.0    1.0             8.0   163.0    65.0  24.46   76.0   \n",
       "\n",
       "   Date of detection   FBS  systolic  diastolic  \n",
       "0        2012.000000  15.7     120.0       80.0  \n",
       "1        2013.666667   7.3     120.0       80.0  \n",
       "2        2019.000000  17.1     120.0       80.0  \n",
       "3        2015.000000   8.5     150.0       90.0  \n",
       "4        2019.000000   7.9     120.0       80.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_imputer_knn_sklearn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91da87f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                  0\n",
       "Smoke                0\n",
       "Dia_family_mem       0\n",
       "Height               0\n",
       "Weight               0\n",
       "BMI                  0\n",
       "Pulse                0\n",
       "Date of detection    0\n",
       "FBS                  0\n",
       "systolic             0\n",
       "diastolic            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_imputer_knn_sklearn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e73ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Age', 'Smoke', 'Dia_family_mem', 'Height', 'Weight', 'BMI', 'Pulse',\n",
      "       'Date of detection', 'systolic', 'diastolic'],\n",
      "      dtype='object')\n",
      "Mean squared error: 13.83461005945856\n"
     ]
    }
   ],
   "source": [
    "#mutual information\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your data and perform imputation as necessary\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# Separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# Perform feature selection using mutual information\n",
    "k = 10 # Number of features to select\n",
    "X_imputed = KNNImputer().fit_transform(X) # Impute missing values if any\n",
    "selector = SelectKBest(mutual_info_regression, k=k)\n",
    "selector.fit(X_imputed, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = selector.get_support()\n",
    "\n",
    "# Train and evaluate KNN with selected features\n",
    "X_selected = X_imputed[:, selected_features]\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_selected, y)\n",
    "\n",
    "# Make predictions on the training set and compute the mean squared error\n",
    "y_pred = knn.predict(X_selected)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "print(f\"Selected features: {X.columns[selected_features]}\")\n",
    "print(f\"Mean squared error: {mse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048e75a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Dia_family_mem', 'Height', 'Weight', 'diastolic'], dtype='object')\n",
      "Mean squared error: 13.381507874439464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your data and perform imputation as necessary\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# Separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# Binarize the target variable\n",
    "threshold = 20\n",
    "y_train = (y > threshold).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature selection using chi2\n",
    "k = 10 # Number of features to select\n",
    "X_train_imputed = KNNImputer().fit_transform(X_train) # Impute missing values if any\n",
    "selector = SelectKBest(chi2, k=4)\n",
    "selector.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "\n",
    "# Train and evaluate KNN with selected features\n",
    "X_train_selected = X_train_imputed[:, selector.get_support()]\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "X_test_imputed = KNNImputer().fit_transform(X_test) # Impute missing values if any\n",
    "X_test_selected = X_test_imputed[:, selector.get_support()]\n",
    "y_pred = knn.predict(X_test_selected)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Mean squared error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b61df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Smoke', 'Dia_family_mem', 'Height', 'Weight', 'BMI', 'Pulse',\n",
      "       'Date of detection', 'systolic', 'diastolic'],\n",
      "      dtype='object')\n",
      "MSE with 10 selected features: 24.8898\n",
      "R2 Score: 0.0319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# Separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the pipeline with imputer, scaler and knn regressor\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# define the number of features to select\n",
    "n_features = 10\n",
    "\n",
    "# define the SelectKBest feature selector\n",
    "selector = SelectKBest(score_func=f_regression, k=n_features)\n",
    "\n",
    "# fit the selector on the training data\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# get the selected features\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(selected_features)\n",
    "\n",
    "# transform the testing data to keep only the selected features\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# train the KNN regressor with the selected features\n",
    "reg_selected = KNeighborsRegressor()\n",
    "reg_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# evaluate the model performance\n",
    "mse = mean_squared_error(y_test, reg_selected.predict(X_test_selected))\n",
    "print(f\"MSE with {n_features} selected features: {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb9f830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Age', 'Dia_family_mem', 'Weight', 'BMI', 'Pulse', 'Date of detection',\n",
      "       'systolic', 'diastolic'],\n",
      "      dtype='object')\n",
      "Mean Squared Error: 24.6786\n",
      "R2 Score: -0.0379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the Lasso regression model with alpha=0.1\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# fit the model on the training data\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# print the selected features\n",
    "print('Selected features:', X.columns[lasso.coef_ != 0])\n",
    "\n",
    "# predict on the testing data\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# evaluate the model performance using Mean Squared Error and R2 score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e744f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 25.8342\n",
      "R2 Score: -0.0865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# feature selection with Ridge Regression\n",
    "selector = SelectFromModel(Ridge(alpha=1.0))\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "X_train_selected = selector.transform(X_train_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# train Ridge Regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred = ridge_model.predict(X_test_selected)\n",
    "\n",
    "# evaluate the model using metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error: {:.4f}\".format(mse))\n",
    "print(\"R2 Score: {:.4f}\".format(r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecda71fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Age', 'Smoke', 'Dia_family_mem', 'Height', 'Weight', 'BMI', 'Pulse',\n",
      "       'Date of detection', 'systolic', 'diastolic'],\n",
      "      dtype='object')\n",
      "Mean Squared Error: 17.32685922389509\n",
      "R2 Score: 0.03188855135381996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# Separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# Create a linear regression object as the estimator\n",
    "estimator = LinearRegression()\n",
    "\n",
    "# Create a recursive feature elimination object with the estimator and MSE as the evaluation metric\n",
    "rfe = RFE(estimator=estimator, n_features_to_select=15)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "\n",
    "# Fit the estimator on the selected features\n",
    "estimator.fit(X[selected_features], y)\n",
    "\n",
    "# Predict the target variable\n",
    "y_pred = estimator.predict(X[selected_features])\n",
    "\n",
    "# Evaluate the performance using mean squared error and r2 score\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb7a34cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k should be >=0, <= n_features = 10; got 15. Use k='all' to return all features.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_408\\862923220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# define the feature selection method and select k best features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_regression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mX_train_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mX_test_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    405\u001b[0m             )\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    605\u001b[0m                 \u001b[1;34m\"k should be >=0, <= n_features = %d; got %r. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;34m\"Use k='all' to return all features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: k should be >=0, <= n_features = 10; got 15. Use k='all' to return all features."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the feature selection method and select k best features\n",
    "selector = SelectKBest(f_regression, k=15)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# fit a linear regression model on the selected features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# evaluate the model performance on the testing data\n",
    "y_pred = model.predict(X_test_selected)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b66ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the elastic net model\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model performance on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# create a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# fit the random forest regressor on the training data\n",
    "rf.fit(X, y)\n",
    "\n",
    "# get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# get names of the top 10 features\n",
    "top_features = X.columns[indices][:10]\n",
    "print(top_features)\n",
    "\n",
    "# select only the top 10 features\n",
    "X_top = X[top_features]\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit the random forest regressor on the training data with top features\n",
    "rf_top = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_top.fit(X_train, y_train)\n",
    "\n",
    "# predict on the testing data with top features\n",
    "y_pred = rf_top.predict(X_test)\n",
    "\n",
    "# evaluate the model performance on the testing data\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('updated_datasetknn.csv')\n",
    "\n",
    "# separate the input features and target variable\n",
    "X = df.drop('FBS', axis=1)\n",
    "y = df['FBS']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the model with Extra Trees Regressor\n",
    "model = ExtraTreesRegressor()\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model performance on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b03eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
